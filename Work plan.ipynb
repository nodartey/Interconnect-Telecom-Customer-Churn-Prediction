{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Work Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interconnect Telecom Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "**For the telecom provider Interconnect, we create a machine learning prototype in this project to forecast client attrition. In addition to internet and phone services, the company offers cloud storage, streaming, and antivirus software.**\n",
    "**Interconnect Telecom can lower churn and increase long-term income by recognizing customers who are likely to depart and offering tailored promotions and retention offers.**\n",
    "\n",
    "**Below is the prepared work plan provided in carrying out the project on Interconnect Telecom Customer churn predictions.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data\n",
    "- import necessary libraries to work for the project.\n",
    "- Load `contract.csv`, `personal.csv`, `internet.csv`, and `phone.csv`.\n",
    "\n",
    "- Inspect each dataset: dimensions, missing values, column types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libriaries\n",
    "import pandas as pd\n",
    "\n",
    "# loading data\n",
    "df_contract = pd.read_csv('/datasets/final_provider/contract.csv')\n",
    "df_personal = pd.read_csv('/datasets/final_provider/personal.csv')\n",
    "df_internet = pd.read_csv('/datasets/final_provider/internet.csv')\n",
    "df_phone = pd.read_csv('/datasets/final_provider/phone.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Inspect Basic Info, Missing Values and Duplicates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contract Dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   BeginDate         7043 non-null   object \n",
      " 2   EndDate           7043 non-null   object \n",
      " 3   Type              7043 non-null   object \n",
      " 4   PaperlessBilling  7043 non-null   object \n",
      " 5   PaymentMethod     7043 non-null   object \n",
      " 6   MonthlyCharges    7043 non-null   float64\n",
      " 7   TotalCharges      7043 non-null   object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 440.3+ KB\n",
      "None\n",
      "customerID          0\n",
      "BeginDate           0\n",
      "EndDate             0\n",
      "Type                0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "dtype: int64 \n",
      "\n",
      "--- Personal Dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   customerID     7043 non-null   object\n",
      " 1   gender         7043 non-null   object\n",
      " 2   SeniorCitizen  7043 non-null   int64 \n",
      " 3   Partner        7043 non-null   object\n",
      " 4   Dependents     7043 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 275.2+ KB\n",
      "None\n",
      "customerID       0\n",
      "gender           0\n",
      "SeniorCitizen    0\n",
      "Partner          0\n",
      "Dependents       0\n",
      "dtype: int64 \n",
      "\n",
      "--- Internet Dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5517 entries, 0 to 5516\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   customerID        5517 non-null   object\n",
      " 1   InternetService   5517 non-null   object\n",
      " 2   OnlineSecurity    5517 non-null   object\n",
      " 3   OnlineBackup      5517 non-null   object\n",
      " 4   DeviceProtection  5517 non-null   object\n",
      " 5   TechSupport       5517 non-null   object\n",
      " 6   StreamingTV       5517 non-null   object\n",
      " 7   StreamingMovies   5517 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 344.9+ KB\n",
      "None\n",
      "customerID          0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "dtype: int64 \n",
      "\n",
      "--- Phone Dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6361 entries, 0 to 6360\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   customerID     6361 non-null   object\n",
      " 1   MultipleLines  6361 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 99.5+ KB\n",
      "None\n",
      "customerID       0\n",
      "MultipleLines    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check structure and missing values\n",
    "for name, df in zip(['Contract', 'Personal', 'Internet', 'Phone'],\n",
    "                    [df_contract, df_personal, df_internet, df_phone]):\n",
    "    print(f\"--- {name} Dataset ---\")\n",
    "    print(df.info())\n",
    "    print(df.isna().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contract Dataset ---\n",
      "Total rows: 7043\n",
      "Duplicate rows: 0\n",
      "\n",
      "--- Personal Dataset ---\n",
      "Total rows: 7043\n",
      "Duplicate rows: 0\n",
      "\n",
      "--- Internet Dataset ---\n",
      "Total rows: 5517\n",
      "Duplicate rows: 0\n",
      "\n",
      "--- Phone Dataset ---\n",
      "Total rows: 6361\n",
      "Duplicate rows: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in each dataset\n",
    "for name, df in zip(['Contract', 'Personal', 'Internet', 'Phone'],\n",
    "                    [df_contract, df_personal, df_internet, df_phone]):\n",
    "    duplicate_count = df.duplicated().sum()\n",
    "    print(f\"--- {name} Dataset ---\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Duplicate rows: {duplicate_count}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Merge the Datasets\n",
    "We will now merge the four datasets on the customerID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7043 entries, 0 to 7042\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   BeginDate         7043 non-null   object \n",
      " 2   EndDate           7043 non-null   object \n",
      " 3   Type              7043 non-null   object \n",
      " 4   PaperlessBilling  7043 non-null   object \n",
      " 5   PaymentMethod     7043 non-null   object \n",
      " 6   MonthlyCharges    7043 non-null   float64\n",
      " 7   TotalCharges      7043 non-null   object \n",
      " 8   gender            7043 non-null   object \n",
      " 9   SeniorCitizen     7043 non-null   int64  \n",
      " 10  Partner           7043 non-null   object \n",
      " 11  Dependents        7043 non-null   object \n",
      " 12  InternetService   5517 non-null   object \n",
      " 13  OnlineSecurity    5517 non-null   object \n",
      " 14  OnlineBackup      5517 non-null   object \n",
      " 15  DeviceProtection  5517 non-null   object \n",
      " 16  TechSupport       5517 non-null   object \n",
      " 17  StreamingTV       5517 non-null   object \n",
      " 18  StreamingMovies   5517 non-null   object \n",
      " 19  MultipleLines     6361 non-null   object \n",
      "dtypes: float64(1), int64(1), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Step-by-step merge on 'customerID'\n",
    "df_merged = df_contract.merge(df_personal, on='customerID', how='left')\n",
    "df_merged = df_merged.merge(df_internet, on='customerID', how='left')\n",
    "df_merged = df_merged.merge(df_phone, on='customerID', how='left')\n",
    "\n",
    "# Display basic info of the merged dataset\n",
    "print(\"Merged dataset:\")\n",
    "print(df_merged.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- I will analyze churn distribution.\n",
    "\n",
    "- I will analyze numerical and categorical features by churn.\n",
    "\n",
    "- I will identify potential correlations or strong predictors.\n",
    "\n",
    "- I will visualize key trends and relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering\n",
    "- Encoding categorical variables using OneHot encoding.\n",
    "- Engineering relevant features (e.g., contract length, total services used, tenure).\n",
    "- I wil Scale numerical features (for models like Logistic Regression or SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use train/test split (e.g., 80/20).\n",
    "\n",
    "- Consider stratification by churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and compare several models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression (baseline)\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Gradient Boosting\n",
    "\n",
    "     - XGBoost\n",
    "     - CatBoost\n",
    "     - LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use stratified K-fold CV (e.g., 5-fold) to evaluate AUC-ROC and accuracy.\n",
    "\n",
    "- Track overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate all models on test data:\n",
    "\n",
    "- AUC-ROC (main metric)\n",
    "\n",
    "- Accuracy, precision, recall, F1-score\n",
    "\n",
    "- Confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Model Selection & Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the best-performing model based on AUC-ROC.\n",
    "\n",
    "- Perform hyperparameter tuning using GridSearchCV or RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion & Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summarize model performance (metric scores).\n",
    "\n",
    "- Justify final model selection.\n",
    "\n",
    "- Discuss important features driving churn.\n",
    "\n",
    "- Provide business insights e.g., which groups are most at risk of churning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Reviewer's comment</b> <a class=\"tocSkip\"></a>\n",
    "This looks like a good plan, nice job with sectioning it out! Build your project out to fill in these sections, best of luck!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
